{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/anujshah/Downloads/nurse-summary-automation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from src.audio_processing.transcriber import load_model, transcribe_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model: large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/__init__.py:65: UserWarning: /Users/anujshah/.cache/whisper/large-v3.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████| 2.88G/2.88G [1:59:29<00:00, 431kiB/s]\n",
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load Whisper model\n",
    "model = load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two texts.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): The first text string.\n",
    "        text2 (str): The second text string.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score between text1 and text2.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transcriptions(audio_dir, transcription_dir, model):\n",
    "    \"\"\"\n",
    "    Evaluate the transcriptions of all audio files in a directory.\n",
    "\n",
    "    Args:\n",
    "        audio_dir (str): Directory containing the audio files.\n",
    "        transcription_dir (str): Directory containing the expected transcription text files.\n",
    "        model: Loaded Whisper model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with audio file names and their corresponding similarity scores.\n",
    "    \"\"\"\n",
    "    audio_files = sorted([f for f in os.listdir(audio_dir) if f.endswith('.mp3')])\n",
    "    scores = {}\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        print(f\"Processing {audio_file}...\")\n",
    "        \n",
    "        # Transcribe the audio file\n",
    "        audio_path = os.path.join(audio_dir, audio_file)\n",
    "        transcribed_text = transcribe_audio(audio_path, model)\n",
    "        \n",
    "        # Load the expected transcription\n",
    "        expected_file = os.path.splitext(audio_file)[0] + '_0.txt'\n",
    "        expected_path = os.path.join(transcription_dir, expected_file)\n",
    "        \n",
    "        with open(expected_path, 'r') as file:\n",
    "            expected_text = file.read()\n",
    "        \n",
    "        # Compute similarity between transcribed text and expected text\n",
    "        similarity_score = compute_similarity(transcribed_text, expected_text)\n",
    "        scores[audio_file] = similarity_score\n",
    "        print(f\"Similarity score for {audio_file}: {similarity_score:.2f}\\n\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mom 4 - 1.mp3...\n",
      "Transcribing audio file: data/test/audio/Mom 4 - 1.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Similarity score for Mom 4 - 1.mp3: 0.97\n",
      "\n",
      "Processing Neeraj 5.mp3...\n",
      "Transcribing audio file: data/test/audio/Neeraj 5.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Similarity score for Neeraj 5.mp3: 0.96\n",
      "\n",
      "Processing Rohan Note 1.mp3...\n",
      "Transcribing audio file: data/test/audio/Rohan Note 1.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Similarity score for Rohan Note 1.mp3: 0.97\n",
      "\n",
      "Processing Tanay 3.mp3...\n",
      "Transcribing audio file: data/test/audio/Tanay 3.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Similarity score for Tanay 3.mp3: 0.98\n",
      "\n",
      "Processing Woman note 2.mp3...\n",
      "Transcribing audio file: data/test/audio/Woman note 2.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujshah/Downloads/nurse-summary-automation/venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Similarity score for Woman note 2.mp3: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "audio_dir = 'data/test/audio'\n",
    "transcription_dir = 'data/test/transcriptions'\n",
    "\n",
    "# Evaluate transcriptions and get scores\n",
    "similarity_scores = evaluate_transcriptions(audio_dir, transcription_dir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity score is 0.9723360397795615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the scores dictionary to a DataFrame for better visualization\n",
    "scores_df = pd.DataFrame(list(similarity_scores.items()), columns=['Audio File', 'Similarity Score'])\n",
    "\n",
    "# Sort by similarity score\n",
    "scores_df = scores_df.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Display the scores\n",
    "print(f\"Average similarity score is {scores_df[\"Similarity Score\"].mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
